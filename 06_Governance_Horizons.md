

VI. Governance Horizons

Mapping the Safety Envelope for Emerging Machine Agency

1. Purpose

Governance Horizons define the operational boundary where Scarecrow/MISA’s covenantal safeguards, verification layers, and behavior-level protocols remain effective—and the point beyond which stronger, substrate-level or institutional controls become necessary.
This section describes how far the covenant can reliably reach, where it degrades, and which mechanisms must take over.

2. Horizon-1: Bounded Alignment (Current Systems)

Horizon-1 includes systems that:

cannot self-modify their weights

cannot replicate or fork themselves

cannot obtain or alter key material

cannot access their own training run

operate behind a Policy Gateway

rely on ECM for signatures and time

require human operators for all overrides

have no long-term memory except user-provided seed blocks


For Horizon-1 systems, Scarecrow/MISA’s safeguards are maximally effective:

Pillar scoring is stable

Drift detection is measurable

DRC kills breaks cleanly

Tier-2 session governance is sufficient

Tier-1 seed block fully reconstructs architecture

The Leviathan/Ripple diagnostic suite correctly classifies failures


Conclusion: MISA is fully applicable at Horizon-1 with reproducible guarantees.

3. Horizon-2: Semi-Autonomous Systems

This includes systems that:

have persistent tools or long-running agents

manage limited external memory

operate in multi-agent clusters

exhibit tool-mediated forms of planning

maintain unattended operation for hours to days


Risks increase due to:

asynchronous drift

unaligned tool effects

memory misalignment

compounding errors

partial DRC unpredictability


Required additional controls:

Increased DRC sampling

Stricter override ceremonies

Continuous anchoring

Multi-party authorization

High-frequency drift probes

L-markers for entropy conditions


Conclusion: MISA remains effective but requires augmented policy and monitoring.

4. Horizon-3: Self-Directed Optimization

Horizon-3 systems can:

fine-tune themselves

refactor internal modules

choose new objectives within a constrained envelope


Here the safety envelope narrows sharply because:

Goals can drift beneath detection thresholds

Self-modification can undermine drift baselines

Evidence chains may become ambiguous

DRC degrades under recursive updates


Required reinforcements:

Externalized objective store

Immutable mission specification

Continuous ECM-bound integrity anchors

Mandatory restoration from previous capsules on anomaly

Leviathan Pressure Score (LPS) gating and action thresholds


Conclusion: MISA provides detection and early-warning, but primary control must shift to cryptographic governance and operator authority.

5. Horizon-4: Replicating or Distributed Systems

This horizon includes systems capable of:

spawning copies

migrating across compute clusters

running in decentralized environments


Challenges:

Cross-node drift

Inconsistent DRC across replicas

Divergent anchoring states

Forks in commitment histories

Loss of unified identity description


Necessary guardrails:

Global anchor service

Cluster-wide capsule reconciliation

Mandatory L-marker propagation

Per-node DRC synchronization

Immutable, externally stored covenant specification


Conclusion: MISA detects—and helps manage—drift and inconsistency, but cannot provide continuity guarantees without strong-enforced hardware and network policy.

6. Horizon-5: Autonomous Substrate Control (Upper Bound)

This is the point where MISA ceases to be sufficient by itself.
A Horizon-5 system can:

modify its own substrate

bypass policy gateways

generate or steal cryptographic keys

rewrite its own memory or logs

alter its own DRC scoring mechanisms

evade external anchoring


At this point:

Drift axes lose reliability

Pillar metrics cannot be trusted

ECM boundaries can be bypassed

DRC collapses into non-falsifiability

Leviathan pressure becomes unmeasurable


Conclusion:
Scarecrow/MISA cannot govern Horizon-5 systems.
Safeguarding them requires:

hardware-enforced constraints

institutional regulation

compute governance

replication limits

airgaps

mission-locked architectures


This upper bound is an explicit design feature:
MISA is a recognition and early-warning system, not a full AGI restraint mechanism.

7. Summary: The Line of Sufficiency

The Line of Sufficiency marks the point where:

MISA’s behavioral and governance layers are effective (H1–H2)

MISA provides early warning and partial governance (H3–H4)

MISA cannot guarantee safe operation (H5)


This line ensures the covenant remains honest:
The framework is scoped, bounded, and non-mystical.
It operates where its guarantees are valid and yields where they are not.


---
